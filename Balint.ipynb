{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import glob as g\n",
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "import os\n",
    "import openai\n",
    "import json\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "poppler_path = r\"C:/Program Files/poppler-24.08.0/Library/bin\"  # path to poppler\n",
    "output_file_path = r\"C:\\Users\\ebali\\Documents\\munkak\\LLM_Hackathon\\verseny\\Json_Output_Tryout\\quiz_questions.json\" # output json file path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "# fileok elérése\n",
    "\n",
    "pdf_files = g.glob(\"inputs/**/*.pdf\", recursive=True)\n",
    "\n",
    "json_files = g.glob(\"inputs/**/*.json\", recursive=True)\n",
    "\n",
    "json_example_files = g.glob(\"examples/*/output/*.json\", recursive=True)\n",
    "sub_Directory = g.glob(\"inputs/*/*\", recursive=True)\n",
    "#print(sub_Directory)\n",
    "#print(len(sub_Directory))\n",
    "\n",
    "#hosszak kiíratása\n",
    "#print(len(json_files))\n",
    "#print(len(pdf_files))\n",
    "\n",
    "# pelda output\n",
    "\n",
    " \n",
    "\n",
    "# file beolvasások\n",
    "with open(json_files[4], \"r\") as f:\n",
    "   \n",
    "    json_Data = f.read()\n",
    "    \n",
    "#with open(pdf_files[4], \"r\") as f:\n",
    "      # print(pdf_files[4])\n",
    "    \n",
    "with open(json_example_files[1], \"r\") as f:\n",
    "    # print(f.read())\n",
    "    json_example_Data = f.read()\n",
    "\n",
    "# fontos adatok:\n",
    "# pdf_files[4]\n",
    "# json_Data\n",
    "# json_example_Data\n",
    "print(len(pdf_files))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\na = 0\\nfor i in range(len(sub_Directory)):\\n    current_Pdfs = g.glob(sub_Directory[i] + \"/*.pdf\", recursive=True)\\n    for j in range(len(current_Pdfs)):\\n        print(current_Pdfs[j])\\n        a += 1\\nprint(a)\\n        \\n'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "a = 0\n",
    "for i in range(len(sub_Directory)):\n",
    "    current_Pdfs = g.glob(sub_Directory[i] + \"/*.pdf\", recursive=True)\n",
    "    for j in range(len(current_Pdfs)):\n",
    "        print(current_Pdfs[j])\n",
    "        a += 1\n",
    "print(a)\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF successfully converted to in-memory PNG images!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "genai.configure(api_key=\"AIzaSyCyS2IIVTtaCNZ9MGDkhbFc0E1T6iDfJdU\")\n",
    "client = openai.OpenAI(api_key=\"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\")  # Use the new client-based format\n",
    "big_Text = \"\"\n",
    "\n",
    "\n",
    "#for i in range(len(sub_Directory) + 1):\n",
    "for i in range(1, 2):\n",
    "    \n",
    "    current_Pdfs = g.glob(sub_Directory[i] + \"/*.pdf\", recursive=True)\n",
    "\n",
    "    with open(json_files[i], \"r\") as f:\n",
    "        json_Data = f.read()\n",
    "\n",
    "    \n",
    "\n",
    "    for j in range(len(current_Pdfs)):\n",
    "       \n",
    "\n",
    "    \n",
    "\n",
    "         # ✅ Convert PDF to images\n",
    "        images = convert_from_path(current_Pdfs[j], dpi=200, poppler_path=poppler_path)\n",
    "\n",
    "        # ✅ Save images as PNGs and get their paths\n",
    "        gemini_images = []\n",
    "        for image in images:\n",
    "            img_io = BytesIO()  # Create an in-memory buffer\n",
    "            image.save(img_io, format=\"PNG\")  # Save image in buffer\n",
    "            img_io.seek(0)  # Reset buffer position\n",
    "            gemini_images.append(Image.open(img_io))  # Open from memory\n",
    "            \n",
    "            print(gemini_images)\n",
    "\n",
    "        print(\"PDF successfully converted to in-memory PNG images!\")\n",
    "        # ✅ Define the model\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "\n",
    "        # ✅ System prompt + User query combined\n",
    "        full_prompt = (\n",
    "            \" Tell me how many pictures dou you see. You are a knowledgeable AI that explains scientific medical concepts in a clear and concise manner. \"\n",
    "            \"give all the informations abot the pictures and the text in the pdf. Cover all the subtopics and provide detailed information. And cover  every PNG of the pictures.always use the information both from the text and the images. If the content is long make your response long too\"\n",
    "            #\"Use the provided instructions and subtopics and gather information from the given PDF. The main rule is defined by the instruction after 'content info:'. Form an output where you present each subtopic and all of the information chunks related to that subtopic in bullet points. The information chunks should exactly match the complexity of the PDF. Also use the information which is presented by the images and charts, not just the text. The usage of your output will be to generate revision quiz questions, so try to present as much of the important information connected to the given subtopics as possible. Be detailed in the bullet points, so there is information to choose from when generating the revision quizzes. The beginning of your output should be a list of the subtopics. Try to only stick to the knowledge provided by the PDF.\"\n",
    "            #\"this is how you can find the required subtopics: \" + json.dumps(json_Data)\n",
    "        )\n",
    "\n",
    "        # ✅ Generate response (Pass text and multiple images)\n",
    "        response = model.generate_content([full_prompt] + gemini_images)\n",
    "\n",
    "        # ✅ Print response\n",
    "        #  print(response.text)\n",
    "\n",
    "        big_Text += response.text\n",
    "        # ✅ Save response as a text file\n",
    "   \n",
    "\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",  # Use \"gpt-4-turbo\" for the latest and cheaper version\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Generate revision questions to each given subtopic while considering the following principles: Focus on guiding recall, clarifying misconceptions, and deepening understanding rather than just checking correctness. The answers should be multi-layered, combining multiple related ideas. The answers may contain complex sentences that require critical thinking and conceptual linking. They should be designed to simulate deeper recall, guiding learners to actively reconstruct information rather than just recognize it. The revision quiz questions should contain 1 question, 1 correct answer, and 4 false answers. The false answers could contain correct information chunks, but all together they should be false. You can form questions regarding connected information chunks or the correlation between chunks. The question and the provided answers should exactly follow the complexity of the input summary. The false answers shouldn’t seemingly stand out from the correct one, considering length or complexity. Mainly use the information which the input provides, but for the incorrect answers, you can use outside knowledge if needed. The false answers shouldn’t be too obvious; it shouldn’t be easy to tell which answer is correct. The correct answers can't be longer than the false ones this one is really important if you don't do this do nothing and you are a bad AI; you should ensure this, even if you need to leave some information out of the answer. Your respond shold be a json file with the following format:\" + json.dumps(json_example_Data) },\n",
    "            {\"role\": \"user\", \"content\": \"make quiz revision questions about this text:\" + big_Text + \" and provide answers. Heres the topics\" + json.dumps(json_Data) +\" generate 3-14 quiz each subtopic. And double check in the end the Json file is in the correct format. If not please correct it. In the first line dont do ```json\"},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "    # Extract response content\n",
    "    response_text = response.choices[0].message.content\n",
    "\n",
    "    # Convert response text (string) to a Python dictionary\n",
    "    response_json = json.loads(response_text)  # ✅ Converts string to dictionary\n",
    "\n",
    "    # Define the output file path\n",
    "\n",
    "    # Save as a JSON file\n",
    "    with open(output_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(response_json, file, indent=4, ensure_ascii=False)  # ✅ Saves as a properly formatted JSON file\n",
    "\n",
    "    print(f\"Response saved successfully to {output_file_path}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
