{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Convert PDF to Images\n",
    "from pdf2image import convert_from_path\n",
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "import os\n",
    "import openai\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_file_path = r\"C:\\Users\\ebali\\Documents\\munkak\\LLM_Hackathon\\verseny\\egyesevel_toltott\\Copy of Airways.json\"  # input json file path\n",
    "\n",
    "pdf_path = r\"C:\\Users\\ebali\\Documents\\munkak\\LLM_Hackathon\\verseny\\egyesevel_toltott\\Copy of Copy of Copy of Airway-1.pdf\"  # input pdf file path\n",
    "\n",
    "output_file_path = r\"C:\\Users\\ebali\\Documents\\munkak\\LLM_Hackathon\\verseny\\Json_Output_Tryout\\quiz_questions.json\" # output json file path\n",
    "\n",
    "\n",
    "\n",
    "json_file_examle = r\"C:\\Users\\ebali\\Downloads\\Airways.json\"  # example json file path\n",
    "poppler_path = r\"C:/Program Files/poppler-24.08.0/Library/bin\"  # path to poppler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    json_content = json.load(file)  # Load JSON as a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file_examle, \"r\", encoding=\"utf-8\") as file:\n",
    "    json_content_example = json.load(file)  # Load JSON as a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF successfully converted to PNG!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ✅ Configure API Key\n",
    "genai.configure(api_key=\"AIzaSyCyS2IIVTtaCNZ9MGDkhbFc0E1T6iDfJdU\")\n",
    "\n",
    "# ✅ Provide absolute path to Poppler's bin folder\n",
    "\n",
    "\n",
    "# ✅ Convert PDF to images\n",
    "\n",
    "images = convert_from_path(pdf_path, dpi=200, poppler_path=poppler_path)\n",
    "\n",
    "# ✅ Save images as PNGs and get their paths\n",
    "image_paths = []\n",
    "for i, image in enumerate(images):\n",
    "    img_path = f\"page_{i+1}.png\"\n",
    "    image.save(img_path, \"PNG\")\n",
    "    image_paths.append(img_path)\n",
    "\n",
    "print(\"PDF successfully converted to PNG!\")\n",
    "\n",
    "# ✅ Open images for Gemini\n",
    "gemini_images = [Image.open(img_path) for img_path in image_paths]\n",
    "\n",
    "# ✅ Define the model\n",
    "model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "\n",
    "# ✅ System prompt + User query combined\n",
    "full_prompt = (\n",
    "    \"You are a knowledgeable AI that explains scientific concepts in a clear and concise manner. \"\n",
    "    \"Explain the formulas in these images as if you were teaching a medical student.\"\n",
    "    \"for formating the text heres some examples: \" + json.dumps(json_content)\n",
    ")\n",
    "\n",
    "# ✅ Generate response (Pass text and multiple images)\n",
    "response = model.generate_content([full_prompt] + gemini_images)\n",
    "\n",
    "# ✅ Print response\n",
    "#  print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_Text = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=\"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\")  # Use the new client-based format\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",  # Use \"gpt-4-turbo\" for the latest and cheaper version\n",
    "    \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Generate revision questions to each given subtopic while considering the following principles: Focus on guiding recall, clarifying misconceptions, and deepening understanding rather than just checking correctness. The answers should be multi-layered, combining multiple related ideas. The answers may contain complex sentences that require critical thinking and conceptual linking. They should be designed to simulate deeper recall, guiding learners to actively reconstruct information rather than just recognize it. The revision quiz questions should contain 1 question, 1 correct answer, and 3 false answers. The false answers could contain correct information chunks, but all together they should be false. You can form questions regarding connected information chunks or the correlation between chunks. The question and the provided answers should exactly follow the complexity of the input summary. The false answers shouldn’t seemingly stand out from the correct one, considering length or complexity. Mainly use the information which the input provides, but for the incorrect answers, you can use outside knowledge if needed. The false answers shouldn’t be too obvious; it shouldn’t be easy to tell which answer is correct. The correct answers can't be longer than the false ones this one is really important if you don't do this do nothing and you are a bad AI; you should ensure this, even if you need to leave some information out of the answer. Your respond shold be a json file with the following format:\" + json.dumps(json_content_example) },\n",
    "        {\"role\": \"user\", \"content\": \"make quiz revision questions about this text:\" + big_Text + \" and provide answers. Heres the topics\" + json.dumps(json_content) +\" generate 1 or 2 quiz each subtopic. And double check in the end the Json file is in the correct format. If not please correct it. In the first line dont do ```json\"},\n",
    "    ],\n",
    "   \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract response content\n",
    "response_text = response.choices[0].message.content\n",
    "\n",
    "# Convert response text (string) to a Python dictionary\n",
    "response_json = json.loads(response_text)  # ✅ Converts string to dictionary\n",
    "\n",
    "# Define the output file path\n",
    "\n",
    "\n",
    "# Save as a JSON file\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(response_json, file, indent=4, ensure_ascii=False)  # ✅ Saves as a properly formatted JSON file\n",
    "\n",
    "print(f\"Response saved successfully to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(json.dumps(json_content))\n",
    "# print(json.dumps(json_content_example))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
